### Documentation for Text Chunking and Node Creation Utilities

This module provides utilities for text chunking and creating nodes with embeddings, primarily designed to interact with vector stores such as Weaviate or other embedding-based systems. It includes functions for splitting text into overlapping chunks and generating embedding-enriched `TextNode` objects for use in machine learning pipelines.

#### **Functions**

---

### `chunk_text`
Splits text into chunks of a specific size, with optional overlap.

**Args:**
- `text` (str): The input text to be chunked.
- `chunk_size` (int): The maximum number of characters in each chunk. Default is 1000.
- `overlap` (int): The number of overlapping characters between consecutive chunks. Default is 100.

**Returns:**
- `List[str]`: A list of text chunks.

**Example:**
```python
text = "This is a long document that needs to be split into chunks."
chunks = chunk_text(text, chunk_size=10, overlap=5)
print(chunks)
```

---

### `chunk_text_with_overlap`
Splits text into overlapping chunks based on token count.

**Args:**
- `text` (str): The input text to be chunked.
- `max_tokens` (int): The maximum number of tokens in each chunk. Default is 100.
- `overlap` (int): The number of overlapping tokens between consecutive chunks. Default is 20.

**Returns:**
- `List[str]`: A list of token-based overlapping chunks.

**Example:**
```python
text = "This is a longer document that needs token-level chunking."
chunks = chunk_text_with_overlap(text, max_tokens=10, overlap=2)
print(chunks)
```

---

### `create_node`
Creates a `TextNode` with embeddings from a text chunk.

**Args:**
- `chunk` (str): The text chunk to process.

**Returns:**
- `TextNode`: A `TextNode` object containing the chunk and its embedding.

**Example:**
```python
chunk = "Sample text chunk."
node = await create_node(chunk)
print(node.text, node.embedding)
```

---

### `async_create_nodes`
Asynchronously creates multiple `TextNode` objects from a list of text chunks.

**Args:**
- `chunks` (List[str]): A list of text chunks.

**Returns:**
- `List[TextNode]`: A list of `TextNode` objects, each enriched with embeddings.

**Example:**
```python
chunks = ["Chunk 1", "Chunk 2", "Chunk 3"]
nodes = await async_create_nodes(chunks)
print(nodes)
```

---

#### **Embedding Model Integration**

This module integrates with the Azure OpenAI embedding model. The following configurations are required for embedding generation:

**Environment Variables:**
- `API_Key`: API key for Azure OpenAI.
- `End_point`: Endpoint URL for Azure OpenAI.
- `API_version`: Version of the Azure OpenAI API.

**Model Initialization:**
The `AzureOpenAIEmbedding` is initialized with the following parameters:
```python
azure_embedding = AzureOpenAIEmbedding(
    model="text-embedding-3-small",
    azure_endpoint=azure_endpoint,
    api_key=azure_api_key,
    api_version="2024-02-01",
    azure_deployment="text-embedding-3-small",
)
```

---

#### Example Workflow

```python
from your_module import chunk_text, async_create_nodes

text = "This is a very long text document that needs to be processed."

# Step 1: Chunk the text
chunks = chunk_text(text, chunk_size=1000, overlap=100)

# Step 2: Create nodes asynchronously
nodes = await async_create_nodes(chunks)

# Step 3: Use the nodes in a vector store or downstream ML tasks
for node in nodes:
    print(node.text, node.embedding)
